{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "from linear_models import LinearOneVsAllClassifier\n",
    "from utils import generate_exp_data\n",
    "from mwu import run_mwu\n",
    "from noise_functions_multi import grad_desc_nonconvex\n",
    "import ray\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist_images = np.copy(mnist.train.images)\n",
    "mnist_labels = np.argmax(mnist.train.labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_test_images = mnist.test.images\n",
    "mnist_test_labels = np.argmax(mnist.test.labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_mnist_features = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_models = 10\n",
    "linear_models = []\n",
    "zeroed_features_list = []\n",
    "sparse_training_sets = []\n",
    "for i in xrange(num_models):\n",
    "    sparse_mnist_images = np.copy(mnist_images)\n",
    "    zeroed_features = np.random.randint(0, num_mnist_features, 588)\n",
    "    zeroed_features_list.append(zeroed_features)\n",
    "    sparse_mnist_images[:, zeroed_features] = 0.0\n",
    "    sparse_training_sets.append(sparse_mnist_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def train_model(sparse_mnist_images, mnist_labels):\n",
    "    model = LinearSVC(loss='hinge')\n",
    "    model.fit(sparse_mnist_images, mnist_labels)\n",
    "    return LinearOneVsAllClassifier(10, model.coef_, model.intercept_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process STDOUT and STDERR is being redirected to /tmp/raylogs/.\n",
      "Waiting for redis server at 127.0.0.1:56888 to respond...\n",
      "Waiting for redis server at 127.0.0.1:12825 to respond...\n",
      "Starting local scheduler with the following resources: {'GPU': 0, 'CPU': 4}.\n",
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8906/notebooks/ray_ui22025.ipynb?token=69ca904c63a333114ed121346e71d9a386d1c3d409e9aa5d\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'local_scheduler_socket_names': ['/tmp/scheduler16710789'],\n",
       " 'node_ip_address': '127.0.0.1',\n",
       " 'object_store_addresses': [ObjectStoreAddress(name='/tmp/plasma_store41359419', manager_name='/tmp/plasma_manager77173156', manager_port=12238)],\n",
       " 'redis_address': '127.0.0.1:56888',\n",
       " 'webui_url': 'http://localhost:8906/notebooks/ray_ui22025.ipynb?token=69ca904c63a333114ed121346e71d9a386d1c3d409e9aa5d'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [train_model.remote(train_set, mnist_labels) for train_set in sparse_training_sets]\n",
    "models = ray.get(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_folder = 'generalization_experiment'\n",
    "os.mkdir(exp_folder)\n",
    "os.mkdir(exp_folder + '/models/')\n",
    "os.mkdir(exp_folder + '/results')\n",
    "os.mkdir(exp_folder + '/data/')\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    np.save('{}/models/w_{}.npy'.format(exp_folder, i), model.weights)\n",
    "    np.save('{}/models/b_{}.npy'.format(exp_folder, i), model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 1000\n",
    "X_exp, Y_exp = generate_exp_data(num_points, mnist_test_images, mnist_test_labels, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(exp_folder  + '/data/X_exp.npy', X_exp)\n",
    "np.save(exp_folder  + '/data/Y_exp.npy', X_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 8]\n",
      "[5 8 9]\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# subset_sizes = [5, 10, 25, 50, 100, 150, 250, 500, 750, 1000]\n",
    "subset_sizes = [2, 3]\n",
    "mwu_iters = 1\n",
    "alpha = .5\n",
    "for k in subset_sizes:\n",
    "    chosen_ixs = np.random.choice(range(num_models), k)\n",
    "    chosen_models = []\n",
    "    for ix in chosen_ixs:\n",
    "        chosen_models.append(models[ix])\n",
    "    print chosen_ixs\n",
    "#     weights, noise, loss_history, acc_history, action_loss = run_mwu(chosen_models, mwu_iters, X_exp, Y_exp, alpha,\n",
    "#                                                                      grad_desc_nonconvex)\n",
    "#     np.save(exp_folder + \"/results/\" + \"weights_{}.npy\".format(k), weights)\n",
    "#     np.save(exp_folder + \"/results/\" + \"noise_{}.npy\".format(k), noise)\n",
    "#     np.save(exp_folder + \"/results/\" + \"loss_history_{}.npy\".format(k), loss_history)\n",
    "#     np.save(exp_folder + \"/results/\" + \"acc_history_{}.npy\".format(k), acc_history)\n",
    "#     np.save(exp_folder + \"/results/\" + \"action_loss_{}.npy\".format(k), action_loss)\n",
    "print \"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
